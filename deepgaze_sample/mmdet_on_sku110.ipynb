{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "049b33eb",
   "metadata": {},
   "source": [
    "# purpose : New pretrained file for DeepgazeIIE model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f672b2",
   "metadata": {},
   "source": [
    "## data & frame 준비 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd993430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data path\n",
    "base_path = '/Users/krc/Documents/retail/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32f05db5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.0.dev20220623'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# install check \n",
    "import torch\n",
    "import os\n",
    "import csv\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdbe15ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/krc/Documents/retail/retail_gh/deepgaze_sample'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc2b330f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/krc/Documents/retail\n"
     ]
    }
   ],
   "source": [
    "%cd ../../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "258cee0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #mmdetection installation \n",
    "# !pip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/cu113/torch1.12.0/index.html\n",
    "# !git clone https://github.com/open-mmlab/mmdetection.git\n",
    "# %cd mmdetection\n",
    "# !pip install -r requirements/build.txt\n",
    "# !pip install -v -e .\n",
    "# !pip install mmdet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36fcafd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1조_리테일앤인사이트_기획안발표.pptx',\n",
       " '리테일앤인사이트_RFP.docx',\n",
       " '.DS_Store',\n",
       " 'DeepGazeIIE-1.0.0',\n",
       " 'retail_gh',\n",
       " 'work',\n",
       " 'mmdetection',\n",
       " 'deep_gaze_jup',\n",
       " '1조_리테일앤인사이트_기획안발표_수정1.pptx',\n",
       " 'data',\n",
       " 'reference']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e608e542",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# annotation by csv \n",
    "f =open('/Users/krc/Documents/retail/data/SKU110K_fixed/annotations/annotations_train.csv','r')\n",
    "annotation = csv.reader(f)\n",
    "# image_name,x1,y1,x2,y2,class,image_width,image_height\n",
    "ls_ann = list(annotation)\n",
    "print(ls_ann)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d7ac6af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['image_name', 'x1', 'y1', 'x2', 'y2', 'class', 'image_width', 'image_height']\n",
      "['train_999.jpg', '905', '1589', '1144', '1712', 'object', '2336', '4160']\n",
      "train_999.jpg\n"
     ]
    }
   ],
   "source": [
    "index = ['image_name','x1','y1','x2','y2','class','image_width','image_height']\n",
    "print(index)\n",
    "print(ls_ann[-1])\n",
    "print(ls_ann[-1][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "54440a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# annotation 생성\n",
    "import copy\n",
    "import os.path as osp\n",
    "import cv2\n",
    "import yaml\n",
    "\n",
    "import mmcv\n",
    "import numpy as np\n",
    "\n",
    "from mmdet.datasets.builder import DATASETS\n",
    "from mmdet.datasets.custom import CustomDataset\n",
    "\n",
    "CLASSES = ('object')\n",
    "# cat2label = {k:i for i, k in enumerate(CLASSES)}\n",
    "\n",
    "# 반드시 아래 Decorator 설정 할것.@DATASETS.register_module() 설정 시 force=True를 입력하지 않으면 Dataset 재등록 불가. \n",
    "# @DATASETS.register_module(force=True)\n",
    "# class SKIKU110K(CustomDataset):\n",
    "#   CLASSES = ('object')\n",
    "  \n",
    "  ##### self.data_root: ./kitti_tiny/ self.ann_file: ./kitti_tiny/train.txt self.img_prefix: ./kitti_tiny/training/image_2\n",
    "  #### ann_file: ./kitti_tiny/train.txt\n",
    "  # annotation에 대한 모든 파일명을 가지고 있는 텍스트 파일을 __init__(self, ann_file)로 입력 받고, 이 self.ann_file이 load_annotations()의 인자로 입력\n",
    "def load_annotations(self, ann_file):\n",
    "#     print('##### self.data_root:', self.data_root, 'self.ann_file:', self.ann_file, 'self.img_prefix:', self.img_prefix)\n",
    "#     print('#### ann_file:', ann_file)\n",
    "#    cat2label = {k:i for i, k in enumerate(self.CLASSES)}\n",
    "    # 포맷 중립 데이터를 담을 list 객체\n",
    "    data_infos = []\n",
    "    \n",
    "    for label in ann_file:\n",
    "      filename = label[0]\n",
    "      height, width = label[6],label[7]\n",
    "      # 개별 image의 annotation 정보 저장용 Dict 생성. key값 filename 에는 image의 파일명만 들어감(디렉토리는 제외)\n",
    "      data_info = {'filename': str(filename),\n",
    "                   'width': int(width), 'height': int(height)}\n",
    "\n",
    "      # 오브젝트의 클래스명은 bbox_names로 저장. \n",
    "      bbox_names = label[5]\n",
    "      # bbox 좌표를 저장\n",
    "      bboxes = [int(label[1]),int(label[2]), int(label[3]) -int(label[1]), int(label[4])-int(label[2])]\n",
    "\n",
    "# 굳이? \n",
    "#       # 클래스명이 해당 사항이 없는 대상 Filtering out, 'DontCare'sms ignore로 별도 저장.\n",
    "#       gt_bboxes = []\n",
    "#       gt_labels = []\n",
    "#       gt_bboxes_ignore = []\n",
    "#       gt_labels_ignore = []\n",
    "\n",
    "#       for bbox_name, bbox in zip(bbox_names, bboxes):\n",
    "#         # 만약 bbox_name이 클래스명에 해당 되면, gt_bboxes와 gt_labels에 추가, 그렇지 않으면 gt_bboxes_ignore, gt_labels_ignore에 추가\n",
    "#         if bbox_name in cat2label:\n",
    "#           gt_bboxes.append(bbox)\n",
    "#           # gt_labels에는 class id를 입력\n",
    "#           gt_labels.append(cat2label[bbox_name])\n",
    "#         else:\n",
    "#           gt_bboxes_ignore.append(bbox)\n",
    "#           gt_labels_ignore.append(-1)\n",
    "      # 개별 image별 annotation 정보를 가지는 Dict 생성. 해당 Dict의 value값은 모두 np.array임. \n",
    "      data_anno = {\n",
    "          'bboxes': np.array(bboxes, dtype=np.float32).reshape(-1, 4).tolist(),\n",
    "          'labels':[0],\n",
    "      }\n",
    "      # image에 대한 메타 정보를 가지는 data_info Dict에 'ann' key값으로 data_anno를 value로 저장. \n",
    "      data_info.update(ann=data_anno)\n",
    "      # 전체 annotation 파일들에 대한 정보를 가지는 data_infos에 data_info Dict를 추가\n",
    "      data_infos.append(data_info)\n",
    "\n",
    "    return data_infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "879c19da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# new_ann = load_annotations(CustomDataset,ann_file=ls_ann)\n",
    "# print(new_ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2549aad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    " \n",
    "# with open('/Users/krc/Documents/retail/data/SKU110K_fixed/annotations/train_ann.json', 'w') as f:\n",
    "#     json.dump(new_ann, f,indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fa0e9a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # annotation by csv \n",
    "# f =open('/Users/krc/Documents/retail/data/SKU110K_fixed/annotations/annotations_val.csv','r')\n",
    "# annotation = csv.reader(f)\n",
    "# # image_name,x1,y1,x2,y2,class,image_width,image_height\n",
    "# val_ann = list(annotation)\n",
    "# f.close()\n",
    "\n",
    "# import json\n",
    "# val_ann = load_annotations(CustomDataset,ann_file=val_ann)\n",
    "\n",
    "\n",
    "# with open('/Users/krc/Documents/retail/data/SKU110K_fixed/annotations/val_ann.json', 'w') as f:\n",
    "#     json.dump(val_ann, f,indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18b8124c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/krc/Documents/retail'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fdca04",
   "metadata": {},
   "source": [
    "## DETR 사전 가중치 다운로드 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0c53e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/krc/Documents/retail/mmdetection/')\n",
    "if not os.path.isdir(\"checkpoint\"):\n",
    "    os.mkdir(\"checkpoint\")\n",
    "os.chdir('checkpoint')\n",
    "\n",
    "from requests import get \n",
    "\n",
    "def download(url, file_name):\n",
    "    with open(file_name, \"wb\") as file:   \n",
    "        response = get(url)               \n",
    "        file.write(response.content)\n",
    "\n",
    "\n",
    "# url = \"https://github.com/open-mmlab/mmdetection/tree/master/configs/deformable_detr\"\n",
    "# download(url,\"deformable_detr_r50_16x2_50e_coco_20210419_220030-a12b9512.pth.pth\")\n",
    "\n",
    "os.chdir('/Users/krc/Documents/retail/mmdetection/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26001e18",
   "metadata": {},
   "source": [
    "## wand (굳이..) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f58cc229",
   "metadata": {},
   "outputs": [],
   "source": [
    "#wandb setting first \n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d1f1b595",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "598bf9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install mmcv-full\n",
    "#!pip install terminaltables\n",
    "#!pip install imagecorruptions\n",
    "#!pip install -q pycocotools\n",
    "\n",
    "import mmcv\n",
    "from mmcv.runner import load_checkpoint\n",
    "from mmdet.apis import inference_detector, show_result_pyplot\n",
    "from mmdet.models import build_detector\n",
    "from mmdet.apis import set_random_seed\n",
    "import os.path as osp\n",
    "\n",
    "def set_config():\n",
    "  # 사용할 모델 초기 py 설정\n",
    "  config = '/Users/krc/Documents/retail/mmdetection/configs/deformable_detr/deformable_detr_r50_16x2_50e_coco.py'\n",
    "\n",
    "  # config 불러오기\n",
    "  cfg = mmcv.Config.fromfile(config)\n",
    "\n",
    "  # config 에 base 기록\n",
    "  cfg.base = '/Users/krc/Documents/retail/mmdetection/configs/detr/detr_r50_8x2_150e_coco.py'\n",
    "\n",
    "  # 데이터셋 지정\n",
    "  cfg.dataset_type = 'CustomDataset'\n",
    "\n",
    "  # data_root는 사용자가 저장한 데이터가 있는 폴더 전까지\n",
    "  data_root = '/Users/krc/Documents/retail/data/SKU110K_fixed/'\n",
    "\n",
    "  # class 설정\n",
    "  cfg.classes = ('object',)\n",
    "\n",
    "  # train, val, test 데이터셋에 대한 type, data_root, ann_file, img_prefix 설정\n",
    "\n",
    "  cfg.data.samples_per_gpu=1\n",
    "  cfg.data.workers_per_gpu=0\n",
    "\n",
    "  cfg.data.train.data_root = data_root\n",
    "  cfg.data.train.ann_file = '/Users/krc/Documents/retail/data/SKU110K_fixed/annotations/train_ann.json' \n",
    "  cfg.data.train.img_prefix = 'train/' \n",
    "  cfg.data.train.classes = cfg.classes\n",
    "  cfg.data.train.type = 'CustomDataset'\n",
    "\n",
    "  cfg.data.val.data_root = data_root \n",
    "  cfg.data.val.ann_file = '/Users/krc/Documents/retail/data/SKU110K_fixed/annotations/val_ann.json'\n",
    "  cfg.data.val.img_prefix = 'val/'\n",
    "  cfg.data.val.classes = cfg.classes\n",
    "  cfg.data.val.type = 'CustomDataset'\n",
    "\n",
    "  cfg.data.test.data_root = data_root \n",
    "  cfg.data.test.ann_file = 'test.json'\n",
    "  cfg.data.test.img_prefix = 'test/'\n",
    "  cfg.data.test.classes = cfg.classes\n",
    "  cfg.data.test.type = 'CustomDataset'\n",
    "\n",
    "  # 클래스 수 지정\n",
    "  cfg.model.bbox_head.num_classes = 1\n",
    "#  cfg.model.roi_head.mask_head.num_classes = 1\n",
    "\n",
    "\n",
    "  # 사전 훈련 모델 지정\n",
    "  cfg.checkpoint_config = dict(interval=10,out_dir='work/ch_config/')\n",
    "  cfg.load_from = '/Users/krc/Documents/retail/mmdetection/checkpoint/deformable_detr_r50_16x2_50e_coco_20210419_220030-a12b9512.pth'\n",
    "\n",
    "\n",
    "  # 가중치 저장 위치\n",
    "  cfg.work_dir =  './work/weights/'\n",
    "\n",
    "  # 평가 지표로 설정\n",
    "  cfg.evaluation.metric = ['bbox']\n",
    "\n",
    "  # epoch 설정\n",
    "  cfg.runner = dict(type='EpochBasedRunner', max_epochs=40) \n",
    "\n",
    "  # batch size 설정\n",
    "  cfg.auto_scale_lr = dict(enable=False, base_batch_size=32)\n",
    "\n",
    "  # gpu 설정 및 seed 설정\n",
    "  cfg.seed = 42\n",
    "  cfg.gpu_ids = range(1)\n",
    "  cfg.device= 'cpu' # for local\n",
    "\n",
    "  #wandb setting\n",
    "#   cfg.log_config.hooks = [\n",
    "#         dict(type='TextLoggerHook'),\n",
    "#         dict(type='MMDetWandbHook',\n",
    "#              init_kwargs={\n",
    "#                           'project': 'SKU_DETR',\n",
    "#                           'config': {\"optimizer\" : 'AdamW, default',\n",
    "#                           \"batch_size\" :32,\n",
    "#                           \"epochs\" :40,\n",
    "#                           \"lr_config\" : 'CosineAnnealning' }\n",
    "#                          },\n",
    "#              interval=4,\n",
    "#              log_checkpoint=True,\n",
    "#              log_checkpoint_metadata=True,\n",
    "#              num_eval_images=100,\n",
    "#              bbox_score_thr=0.1)]\n",
    "\n",
    "  #learning rate\n",
    "  cfg.lr_config = dict(\n",
    "   policy='CosineAnnealing',\n",
    "   by_epoch=False,\n",
    "   min_lr=0)\n",
    "    \n",
    "    \n",
    "  meta = dict()\n",
    "  meta['exp_name'] = osp.basename(config)\n",
    "  print(meta)\n",
    "\n",
    "\n",
    "  return cfg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "16811da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'exp_name': 'deformable_detr_r50_16x2_50e_coco.py'}\n"
     ]
    }
   ],
   "source": [
    "cfg = set_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7a42d5b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_type = 'CustomDataset'\n",
      "data_root = 'data/coco/'\n",
      "img_norm_cfg = dict(\n",
      "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(type='RandomFlip', flip_ratio=0.5),\n",
      "    dict(\n",
      "        type='AutoAugment',\n",
      "        policies=[[{\n",
      "            'type':\n",
      "            'Resize',\n",
      "            'img_scale': [(480, 1333), (512, 1333), (544, 1333), (576, 1333),\n",
      "                          (608, 1333), (640, 1333), (672, 1333), (704, 1333),\n",
      "                          (736, 1333), (768, 1333), (800, 1333)],\n",
      "            'multiscale_mode':\n",
      "            'value',\n",
      "            'keep_ratio':\n",
      "            True\n",
      "        }],\n",
      "                  [{\n",
      "                      'type': 'Resize',\n",
      "                      'img_scale': [(400, 4200), (500, 4200), (600, 4200)],\n",
      "                      'multiscale_mode': 'value',\n",
      "                      'keep_ratio': True\n",
      "                  }, {\n",
      "                      'type': 'RandomCrop',\n",
      "                      'crop_type': 'absolute_range',\n",
      "                      'crop_size': (384, 600),\n",
      "                      'allow_negative_crop': True\n",
      "                  }, {\n",
      "                      'type':\n",
      "                      'Resize',\n",
      "                      'img_scale': [(480, 1333), (512, 1333), (544, 1333),\n",
      "                                    (576, 1333), (608, 1333), (640, 1333),\n",
      "                                    (672, 1333), (704, 1333), (736, 1333),\n",
      "                                    (768, 1333), (800, 1333)],\n",
      "                      'multiscale_mode':\n",
      "                      'value',\n",
      "                      'override':\n",
      "                      True,\n",
      "                      'keep_ratio':\n",
      "                      True\n",
      "                  }]]),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_rgb=True),\n",
      "    dict(type='Pad', size_divisor=1),\n",
      "    dict(type='DefaultFormatBundle'),\n",
      "    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        type='MultiScaleFlipAug',\n",
      "        img_scale=(1333, 800),\n",
      "        flip=False,\n",
      "        transforms=[\n",
      "            dict(type='Resize', keep_ratio=True),\n",
      "            dict(type='RandomFlip'),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='Pad', size_divisor=1),\n",
      "            dict(type='ImageToTensor', keys=['img']),\n",
      "            dict(type='Collect', keys=['img'])\n",
      "        ])\n",
      "]\n",
      "data = dict(\n",
      "    samples_per_gpu=1,\n",
      "    workers_per_gpu=0,\n",
      "    train=dict(\n",
      "        type='CustomDataset',\n",
      "        ann_file=\n",
      "        '/Users/krc/Documents/retail/data/SKU110K_fixed/annotations/train_ann.json',\n",
      "        img_prefix='train/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(type='RandomFlip', flip_ratio=0.5),\n",
      "            dict(\n",
      "                type='AutoAugment',\n",
      "                policies=[[{\n",
      "                    'type':\n",
      "                    'Resize',\n",
      "                    'img_scale': [(480, 1333), (512, 1333), (544, 1333),\n",
      "                                  (576, 1333), (608, 1333), (640, 1333),\n",
      "                                  (672, 1333), (704, 1333), (736, 1333),\n",
      "                                  (768, 1333), (800, 1333)],\n",
      "                    'multiscale_mode':\n",
      "                    'value',\n",
      "                    'keep_ratio':\n",
      "                    True\n",
      "                }],\n",
      "                          [{\n",
      "                              'type': 'Resize',\n",
      "                              'img_scale': [(400, 4200), (500, 4200),\n",
      "                                            (600, 4200)],\n",
      "                              'multiscale_mode': 'value',\n",
      "                              'keep_ratio': True\n",
      "                          }, {\n",
      "                              'type': 'RandomCrop',\n",
      "                              'crop_type': 'absolute_range',\n",
      "                              'crop_size': (384, 600),\n",
      "                              'allow_negative_crop': True\n",
      "                          }, {\n",
      "                              'type':\n",
      "                              'Resize',\n",
      "                              'img_scale': [(480, 1333), (512, 1333),\n",
      "                                            (544, 1333), (576, 1333),\n",
      "                                            (608, 1333), (640, 1333),\n",
      "                                            (672, 1333), (704, 1333),\n",
      "                                            (736, 1333), (768, 1333),\n",
      "                                            (800, 1333)],\n",
      "                              'multiscale_mode':\n",
      "                              'value',\n",
      "                              'override':\n",
      "                              True,\n",
      "                              'keep_ratio':\n",
      "                              True\n",
      "                          }]]),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='Pad', size_divisor=1),\n",
      "            dict(type='DefaultFormatBundle'),\n",
      "            dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
      "        ],\n",
      "        filter_empty_gt=False,\n",
      "        data_root='/Users/krc/Documents/retail/data/SKU110K_fixed/',\n",
      "        classes=('object', )),\n",
      "    val=dict(\n",
      "        type='CustomDataset',\n",
      "        ann_file=\n",
      "        '/Users/krc/Documents/retail/data/SKU110K_fixed/annotations/val_ann.json',\n",
      "        img_prefix='val/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(1333, 800),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='Pad', size_divisor=1),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ],\n",
      "        data_root='/Users/krc/Documents/retail/data/SKU110K_fixed/',\n",
      "        classes=('object', )),\n",
      "    test=dict(\n",
      "        type='CustomDataset',\n",
      "        ann_file='test.json',\n",
      "        img_prefix='test/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(1333, 800),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='Pad', size_divisor=1),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ],\n",
      "        data_root='/Users/krc/Documents/retail/data/SKU110K_fixed/',\n",
      "        classes=('object', )))\n",
      "evaluation = dict(interval=1, metric=['bbox'])\n",
      "checkpoint_config = dict(interval=10, out_dir='work/ch_config/')\n",
      "log_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])\n",
      "custom_hooks = [dict(type='NumClassCheckHook')]\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = '/Users/krc/Documents/retail/mmdetection/checkpoint/deformable_detr_r50_16x2_50e_coco_20210419_220030-a12b9512.pth'\n",
      "resume_from = None\n",
      "workflow = [('train', 1)]\n",
      "opencv_num_threads = 0\n",
      "mp_start_method = 'fork'\n",
      "auto_scale_lr = dict(enable=False, base_batch_size=32)\n",
      "model = dict(\n",
      "    type='DeformableDETR',\n",
      "    backbone=dict(\n",
      "        type='ResNet',\n",
      "        depth=50,\n",
      "        num_stages=4,\n",
      "        out_indices=(1, 2, 3),\n",
      "        frozen_stages=1,\n",
      "        norm_cfg=dict(type='BN', requires_grad=False),\n",
      "        norm_eval=True,\n",
      "        style='pytorch',\n",
      "        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet50')),\n",
      "    neck=dict(\n",
      "        type='ChannelMapper',\n",
      "        in_channels=[512, 1024, 2048],\n",
      "        kernel_size=1,\n",
      "        out_channels=256,\n",
      "        act_cfg=None,\n",
      "        norm_cfg=dict(type='GN', num_groups=32),\n",
      "        num_outs=4),\n",
      "    bbox_head=dict(\n",
      "        type='DeformableDETRHead',\n",
      "        num_query=300,\n",
      "        num_classes=1,\n",
      "        in_channels=2048,\n",
      "        sync_cls_avg_factor=True,\n",
      "        as_two_stage=False,\n",
      "        transformer=dict(\n",
      "            type='DeformableDetrTransformer',\n",
      "            encoder=dict(\n",
      "                type='DetrTransformerEncoder',\n",
      "                num_layers=6,\n",
      "                transformerlayers=dict(\n",
      "                    type='BaseTransformerLayer',\n",
      "                    attn_cfgs=dict(\n",
      "                        type='MultiScaleDeformableAttention', embed_dims=256),\n",
      "                    feedforward_channels=1024,\n",
      "                    ffn_dropout=0.1,\n",
      "                    operation_order=('self_attn', 'norm', 'ffn', 'norm'))),\n",
      "            decoder=dict(\n",
      "                type='DeformableDetrTransformerDecoder',\n",
      "                num_layers=6,\n",
      "                return_intermediate=True,\n",
      "                transformerlayers=dict(\n",
      "                    type='DetrTransformerDecoderLayer',\n",
      "                    attn_cfgs=[\n",
      "                        dict(\n",
      "                            type='MultiheadAttention',\n",
      "                            embed_dims=256,\n",
      "                            num_heads=8,\n",
      "                            dropout=0.1),\n",
      "                        dict(\n",
      "                            type='MultiScaleDeformableAttention',\n",
      "                            embed_dims=256)\n",
      "                    ],\n",
      "                    feedforward_channels=1024,\n",
      "                    ffn_dropout=0.1,\n",
      "                    operation_order=('self_attn', 'norm', 'cross_attn', 'norm',\n",
      "                                     'ffn', 'norm')))),\n",
      "        positional_encoding=dict(\n",
      "            type='SinePositionalEncoding',\n",
      "            num_feats=128,\n",
      "            normalize=True,\n",
      "            offset=-0.5),\n",
      "        loss_cls=dict(\n",
      "            type='FocalLoss',\n",
      "            use_sigmoid=True,\n",
      "            gamma=2.0,\n",
      "            alpha=0.25,\n",
      "            loss_weight=2.0),\n",
      "        loss_bbox=dict(type='L1Loss', loss_weight=5.0),\n",
      "        loss_iou=dict(type='GIoULoss', loss_weight=2.0)),\n",
      "    train_cfg=dict(\n",
      "        assigner=dict(\n",
      "            type='HungarianAssigner',\n",
      "            cls_cost=dict(type='FocalLossCost', weight=2.0),\n",
      "            reg_cost=dict(type='BBoxL1Cost', weight=5.0, box_format='xywh'),\n",
      "            iou_cost=dict(type='IoUCost', iou_mode='giou', weight=2.0))),\n",
      "    test_cfg=dict(max_per_img=100))\n",
      "optimizer = dict(\n",
      "    type='AdamW',\n",
      "    lr=0.0002,\n",
      "    weight_decay=0.0001,\n",
      "    paramwise_cfg=dict(\n",
      "        custom_keys=dict(\n",
      "            backbone=dict(lr_mult=0.1),\n",
      "            sampling_offsets=dict(lr_mult=0.1),\n",
      "            reference_points=dict(lr_mult=0.1))))\n",
      "optimizer_config = dict(grad_clip=dict(max_norm=0.1, norm_type=2))\n",
      "lr_config = dict(policy='CosineAnnealing', by_epoch=False, min_lr=0)\n",
      "runner = dict(type='EpochBasedRunner', max_epochs=40)\n",
      "base = '/Users/krc/Documents/retail/mmdetection/configs/detr/detr_r50_8x2_150e_coco.py'\n",
      "classes = ('object', )\n",
      "work_dir = './work/weights/'\n",
      "seed = 42\n",
      "gpu_ids = range(0, 1)\n",
      "device = 'cpu'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cfg.pretty_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2ef93d",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f0c58f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-11 18:12:44,067 - mmdet - INFO - Automatic scaling of learning rate (LR) has been disabled.\n",
      "2022-10-11 18:12:44,370 - mmdet - INFO - load checkpoint from local path: /Users/krc/Documents/retail/mmdetection/checkpoint/deformable_detr_r50_16x2_50e_coco_20210419_220030-a12b9512.pth\n",
      "2022-10-11 18:12:45,027 - mmdet - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "size mismatch for bbox_head.cls_branches.0.weight: copying a param with shape torch.Size([80, 256]) from checkpoint, the shape in current model is torch.Size([1, 256]).\n",
      "size mismatch for bbox_head.cls_branches.0.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([1]).\n",
      "size mismatch for bbox_head.cls_branches.1.weight: copying a param with shape torch.Size([80, 256]) from checkpoint, the shape in current model is torch.Size([1, 256]).\n",
      "size mismatch for bbox_head.cls_branches.1.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([1]).\n",
      "size mismatch for bbox_head.cls_branches.2.weight: copying a param with shape torch.Size([80, 256]) from checkpoint, the shape in current model is torch.Size([1, 256]).\n",
      "size mismatch for bbox_head.cls_branches.2.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([1]).\n",
      "size mismatch for bbox_head.cls_branches.3.weight: copying a param with shape torch.Size([80, 256]) from checkpoint, the shape in current model is torch.Size([1, 256]).\n",
      "size mismatch for bbox_head.cls_branches.3.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([1]).\n",
      "size mismatch for bbox_head.cls_branches.4.weight: copying a param with shape torch.Size([80, 256]) from checkpoint, the shape in current model is torch.Size([1, 256]).\n",
      "size mismatch for bbox_head.cls_branches.4.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([1]).\n",
      "size mismatch for bbox_head.cls_branches.5.weight: copying a param with shape torch.Size([80, 256]) from checkpoint, the shape in current model is torch.Size([1, 256]).\n",
      "size mismatch for bbox_head.cls_branches.5.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([1]).\n",
      "2022-10-11 18:12:45,032 - mmdet - INFO - Start running, host: krc@krcui-iMac-3.local, work_dir: /Users/krc/Documents/retail/mmdetection/work/weights\n",
      "2022-10-11 18:12:45,035 - mmdet - INFO - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       \n",
      "(NORMAL      ) NumClassCheckHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(ABOVE_NORMAL) OptimizerHook                      \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) NumClassCheckHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_run:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "2022-10-11 18:12:45,035 - mmdet - INFO - workflow: [('train', 1)], max: 40 epochs\n",
      "2022-10-11 18:12:45,036 - mmdet - INFO - Checkpoints will be saved to work/ch_config/weights by HardDiskBackend.\n",
      "/Users/krc/miniforge3/envs/pytorch/lib/python3.8/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:2890.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "expected scalar type Float but found Double",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [34]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m model\u001b[38;5;241m.\u001b[39mCLASSES \u001b[38;5;241m=\u001b[39m datasets[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mCLASSES\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# 훈련\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[43mtrain_detector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatasets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistributed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/retail/mmdetection/mmdet/apis/train.py:244\u001b[0m, in \u001b[0;36mtrain_detector\u001b[0;34m(model, dataset, cfg, distributed, validate, timestamp, meta)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m cfg\u001b[38;5;241m.\u001b[39mload_from:\n\u001b[1;32m    243\u001b[0m     runner\u001b[38;5;241m.\u001b[39mload_checkpoint(cfg\u001b[38;5;241m.\u001b[39mload_from)\n\u001b[0;32m--> 244\u001b[0m \u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_loaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mworkflow\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.8/site-packages/mmcv/runner/epoch_based_runner.py:136\u001b[0m, in \u001b[0;36mEpochBasedRunner.run\u001b[0;34m(self, data_loaders, workflow, max_epochs, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_epochs:\n\u001b[1;32m    135\u001b[0m                 \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 136\u001b[0m             \u001b[43mepoch_runner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_loaders\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# wait for some hooks like loggers to finish\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_hook(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_run\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.8/site-packages/mmcv/runner/epoch_based_runner.py:53\u001b[0m, in \u001b[0;36mEpochBasedRunner.train\u001b[0;34m(self, data_loader, **kwargs)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inner_iter \u001b[38;5;241m=\u001b[39m i\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_hook(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_train_iter\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 53\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_iter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_hook(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_train_iter\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_batch\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.8/site-packages/mmcv/runner/epoch_based_runner.py:31\u001b[0m, in \u001b[0;36mEpochBasedRunner.run_iter\u001b[0;34m(self, data_batch, train_mode, **kwargs)\u001b[0m\n\u001b[1;32m     28\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_processor(\n\u001b[1;32m     29\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, data_batch, train_mode\u001b[38;5;241m=\u001b[39mtrain_mode, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m train_mode:\n\u001b[0;32m---> 31\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m                                    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     34\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mval_step(data_batch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.8/site-packages/mmcv/parallel/data_parallel.py:62\u001b[0m, in \u001b[0;36mMMDataParallel.train_step\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_ids:\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;66;03m# We add the following line thus the module could gather and\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;66;03m# convert data containers as those in GPU inference\u001b[39;00m\n\u001b[1;32m     61\u001b[0m     inputs, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscatter(inputs, kwargs, [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m---> 62\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_ids) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m, \\\n\u001b[1;32m     65\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMMDataParallel only supports single GPU training, if you need to\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     66\u001b[0m      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m train with multiple GPUs, please use MMDistributedDataParallel\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     67\u001b[0m      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m chain(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule\u001b[38;5;241m.\u001b[39mbuffers()):\n",
      "File \u001b[0;32m~/Documents/retail/mmdetection/mmdet/models/detectors/base.py:248\u001b[0m, in \u001b[0;36mBaseDetector.train_step\u001b[0;34m(self, data, optimizer)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, data, optimizer):\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;124;03m\"\"\"The iteration step during training.\u001b[39;00m\n\u001b[1;32m    223\u001b[0m \n\u001b[1;32m    224\u001b[0m \u001b[38;5;124;03m    This method defines an iteration step during training, except for the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;124;03m              averaging the logs.\u001b[39;00m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 248\u001b[0m     losses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    249\u001b[0m     loss, log_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_losses(losses)\n\u001b[1;32m    251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m    252\u001b[0m         loss\u001b[38;5;241m=\u001b[39mloss, log_vars\u001b[38;5;241m=\u001b[39mlog_vars, num_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimg_metas\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py:1131\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1130\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1132\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1133\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.8/site-packages/mmcv/runner/fp16_utils.py:116\u001b[0m, in \u001b[0;36mauto_fp16.<locals>.auto_fp16_wrapper.<locals>.new_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m@auto_fp16 can only be used to decorate the \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    114\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmethod of those classes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msupported_types\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mhasattr\u001b[39m(args[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfp16_enabled\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m args[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mfp16_enabled):\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mold_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;66;03m# get the arg spec of the decorated method\u001b[39;00m\n\u001b[1;32m    119\u001b[0m args_info \u001b[38;5;241m=\u001b[39m getfullargspec(old_func)\n",
      "File \u001b[0;32m~/Documents/retail/mmdetection/mmdet/models/detectors/base.py:172\u001b[0m, in \u001b[0;36mBaseDetector.forward\u001b[0;34m(self, img, img_metas, return_loss, **kwargs)\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39monnx_export(img[\u001b[38;5;241m0\u001b[39m], img_metas[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_loss:\n\u001b[0;32m--> 172\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_metas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward_test(img, img_metas, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Documents/retail/mmdetection/mmdet/models/detectors/single_stage.py:83\u001b[0m, in \u001b[0;36mSingleStageDetector.forward_train\u001b[0;34m(self, img, img_metas, gt_bboxes, gt_labels, gt_bboxes_ignore)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28msuper\u001b[39m(SingleStageDetector, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mforward_train(img, img_metas)\n\u001b[1;32m     82\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextract_feat(img)\n\u001b[0;32m---> 83\u001b[0m losses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbbox_head\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_metas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgt_bboxes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mgt_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgt_bboxes_ignore\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m losses\n",
      "File \u001b[0;32m~/Documents/retail/mmdetection/mmdet/models/dense_heads/detr_head.py:579\u001b[0m, in \u001b[0;36mDETRHead.forward_train\u001b[0;34m(self, x, img_metas, gt_bboxes, gt_labels, gt_bboxes_ignore, proposal_cfg, **kwargs)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    578\u001b[0m     loss_inputs \u001b[38;5;241m=\u001b[39m outs \u001b[38;5;241m+\u001b[39m (gt_bboxes, gt_labels, img_metas)\n\u001b[0;32m--> 579\u001b[0m losses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mloss_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgt_bboxes_ignore\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgt_bboxes_ignore\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    580\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m losses\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.8/site-packages/mmcv/runner/fp16_utils.py:205\u001b[0m, in \u001b[0;36mforce_fp32.<locals>.force_fp32_wrapper.<locals>.new_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m@force_fp32 can only be used to decorate the \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    203\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmethod of nn.Module\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mhasattr\u001b[39m(args[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfp16_enabled\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m args[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mfp16_enabled):\n\u001b[0;32m--> 205\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mold_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;66;03m# get the arg spec of the decorated method\u001b[39;00m\n\u001b[1;32m    207\u001b[0m args_info \u001b[38;5;241m=\u001b[39m getfullargspec(old_func)\n",
      "File \u001b[0;32m~/Documents/retail/mmdetection/mmdet/models/dense_heads/deformable_detr_head.py:233\u001b[0m, in \u001b[0;36mDeformableDETRHead.loss\u001b[0;34m(self, all_cls_scores, all_bbox_preds, enc_cls_scores, enc_bbox_preds, gt_bboxes_list, gt_labels_list, img_metas, gt_bboxes_ignore)\u001b[0m\n\u001b[1;32m    228\u001b[0m all_gt_bboxes_ignore_list \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    229\u001b[0m     gt_bboxes_ignore \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_dec_layers)\n\u001b[1;32m    230\u001b[0m ]\n\u001b[1;32m    231\u001b[0m img_metas_list \u001b[38;5;241m=\u001b[39m [img_metas \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_dec_layers)]\n\u001b[0;32m--> 233\u001b[0m losses_cls, losses_bbox, losses_iou \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_apply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_single\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_cls_scores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_bbox_preds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m    \u001b[49m\u001b[43mall_gt_bboxes_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_gt_labels_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_metas_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m    \u001b[49m\u001b[43mall_gt_bboxes_ignore_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m loss_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n\u001b[1;32m    239\u001b[0m \u001b[38;5;66;03m# loss of proposal generated from encode feature map.\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/retail/mmdetection/mmdet/core/utils/misc.py:30\u001b[0m, in \u001b[0;36mmulti_apply\u001b[0;34m(func, *args, **kwargs)\u001b[0m\n\u001b[1;32m     28\u001b[0m pfunc \u001b[38;5;241m=\u001b[39m partial(func, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;28;01melse\u001b[39;00m func\n\u001b[1;32m     29\u001b[0m map_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(pfunc, \u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m---> 30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmap_results\u001b[49m\u001b[43m)\u001b[49m))\n",
      "File \u001b[0;32m~/Documents/retail/mmdetection/mmdet/models/dense_heads/detr_head.py:365\u001b[0m, in \u001b[0;36mDETRHead.loss_single\u001b[0;34m(self, cls_scores, bbox_preds, gt_bboxes_list, gt_labels_list, img_metas, gt_bboxes_ignore_list)\u001b[0m\n\u001b[1;32m    363\u001b[0m cls_scores_list \u001b[38;5;241m=\u001b[39m [cls_scores[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_imgs)]\n\u001b[1;32m    364\u001b[0m bbox_preds_list \u001b[38;5;241m=\u001b[39m [bbox_preds[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_imgs)]\n\u001b[0;32m--> 365\u001b[0m cls_reg_targets \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcls_scores_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox_preds_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mgt_bboxes_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgt_labels_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mimg_metas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgt_bboxes_ignore_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    368\u001b[0m (labels_list, label_weights_list, bbox_targets_list, bbox_weights_list,\n\u001b[1;32m    369\u001b[0m  num_total_pos, num_total_neg) \u001b[38;5;241m=\u001b[39m cls_reg_targets\n\u001b[1;32m    370\u001b[0m labels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(labels_list, \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/retail/mmdetection/mmdet/models/dense_heads/detr_head.py:468\u001b[0m, in \u001b[0;36mDETRHead.get_targets\u001b[0;34m(self, cls_scores_list, bbox_preds_list, gt_bboxes_list, gt_labels_list, img_metas, gt_bboxes_ignore_list)\u001b[0m\n\u001b[1;32m    462\u001b[0m num_imgs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(cls_scores_list)\n\u001b[1;32m    463\u001b[0m gt_bboxes_ignore_list \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    464\u001b[0m     gt_bboxes_ignore_list \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_imgs)\n\u001b[1;32m    465\u001b[0m ]\n\u001b[1;32m    467\u001b[0m (labels_list, label_weights_list, bbox_targets_list,\n\u001b[0;32m--> 468\u001b[0m  bbox_weights_list, pos_inds_list, neg_inds_list) \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_apply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[43m     \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_target_single\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcls_scores_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox_preds_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    470\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgt_bboxes_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgt_labels_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_metas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgt_bboxes_ignore_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    471\u001b[0m num_total_pos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m((inds\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;28;01mfor\u001b[39;00m inds \u001b[38;5;129;01min\u001b[39;00m pos_inds_list))\n\u001b[1;32m    472\u001b[0m num_total_neg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m((inds\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;28;01mfor\u001b[39;00m inds \u001b[38;5;129;01min\u001b[39;00m neg_inds_list))\n",
      "File \u001b[0;32m~/Documents/retail/mmdetection/mmdet/core/utils/misc.py:30\u001b[0m, in \u001b[0;36mmulti_apply\u001b[0;34m(func, *args, **kwargs)\u001b[0m\n\u001b[1;32m     28\u001b[0m pfunc \u001b[38;5;241m=\u001b[39m partial(func, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;28;01melse\u001b[39;00m func\n\u001b[1;32m     29\u001b[0m map_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(pfunc, \u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m---> 30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmap_results\u001b[49m\u001b[43m)\u001b[49m))\n",
      "File \u001b[0;32m~/Documents/retail/mmdetection/mmdet/models/dense_heads/detr_head.py:514\u001b[0m, in \u001b[0;36mDETRHead._get_target_single\u001b[0;34m(self, cls_score, bbox_pred, gt_bboxes, gt_labels, img_meta, gt_bboxes_ignore)\u001b[0m\n\u001b[1;32m    512\u001b[0m num_bboxes \u001b[38;5;241m=\u001b[39m bbox_pred\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    513\u001b[0m \u001b[38;5;66;03m# assigner and sampler\u001b[39;00m\n\u001b[0;32m--> 514\u001b[0m assign_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massigner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massign\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbbox_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcls_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgt_bboxes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mgt_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_meta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mgt_bboxes_ignore\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    517\u001b[0m sampling_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampler\u001b[38;5;241m.\u001b[39msample(assign_result, bbox_pred,\n\u001b[1;32m    518\u001b[0m                                       gt_bboxes)\n\u001b[1;32m    519\u001b[0m pos_inds \u001b[38;5;241m=\u001b[39m sampling_result\u001b[38;5;241m.\u001b[39mpos_inds\n",
      "File \u001b[0;32m~/Documents/retail/mmdetection/mmdet/core/bbox/assigners/hungarian_assigner.py:121\u001b[0m, in \u001b[0;36mHungarianAssigner.assign\u001b[0;34m(self, bbox_pred, cls_pred, gt_bboxes, gt_labels, img_meta, gt_bboxes_ignore, eps)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;66;03m# regression L1 cost\u001b[39;00m\n\u001b[1;32m    120\u001b[0m normalize_gt_bboxes \u001b[38;5;241m=\u001b[39m gt_bboxes \u001b[38;5;241m/\u001b[39m factor\n\u001b[0;32m--> 121\u001b[0m reg_cost \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreg_cost\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbbox_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize_gt_bboxes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;66;03m# regression iou cost, defaultly giou is used in official DETR.\u001b[39;00m\n\u001b[1;32m    123\u001b[0m bboxes \u001b[38;5;241m=\u001b[39m bbox_cxcywh_to_xyxy(bbox_pred) \u001b[38;5;241m*\u001b[39m factor\n",
      "File \u001b[0;32m~/Documents/retail/mmdetection/mmdet/core/bbox/match_costs/match_cost.py:50\u001b[0m, in \u001b[0;36mBBoxL1Cost.__call__\u001b[0;34m(self, bbox_pred, gt_bboxes)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbox_format \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxyxy\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     49\u001b[0m     bbox_pred \u001b[38;5;241m=\u001b[39m bbox_cxcywh_to_xyxy(bbox_pred)\n\u001b[0;32m---> 50\u001b[0m bbox_cost \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcdist\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbbox_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgt_bboxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m bbox_cost \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.8/site-packages/torch/functional.py:1183\u001b[0m, in \u001b[0;36mcdist\u001b[0;34m(x1, x2, p, compute_mode)\u001b[0m\n\u001b[1;32m   1180\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m   1181\u001b[0m         cdist, (x1, x2), x1, x2, p\u001b[38;5;241m=\u001b[39mp, compute_mode\u001b[38;5;241m=\u001b[39mcompute_mode)\n\u001b[1;32m   1182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compute_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muse_mm_for_euclid_dist_if_necessary\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m-> 1183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcdist\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m compute_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muse_mm_for_euclid_dist\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m   1185\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _VF\u001b[38;5;241m.\u001b[39mcdist(x1, x2, p, \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expected scalar type Float but found Double"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Thread SenderThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/krc/miniforge3/envs/pytorch/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 50, in run\n",
      "    self._run()\n",
      "  File \"/Users/krc/miniforge3/envs/pytorch/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 101, in _run\n",
      "    self._process(record)\n",
      "  File \"/Users/krc/miniforge3/envs/pytorch/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 308, in _process\n",
      "    self._sm.send(record)\n",
      "  File \"/Users/krc/miniforge3/envs/pytorch/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 305, in send\n",
      "    send_handler(record)\n",
      "  File \"/Users/krc/miniforge3/envs/pytorch/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 319, in send_request\n",
      "    send_handler(record)\n",
      "  File \"/Users/krc/miniforge3/envs/pytorch/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 486, in send_request_defer\n",
      "    transition_state()\n",
      "  File \"/Users/krc/miniforge3/envs/pytorch/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 464, in transition_state\n",
      "    self._interface.publish_defer(state)\n",
      "  File \"/Users/krc/miniforge3/envs/pytorch/lib/python3.8/site-packages/wandb/sdk/interface/interface_shared.py\", line 285, in publish_defer\n",
      "    self._publish_defer(cast(\"pb.DeferRequest.DeferState.V\", state))\n",
      "  File \"/Users/krc/miniforge3/envs/pytorch/lib/python3.8/site-packages/wandb/sdk/interface/interface_shared.py\", line 282, in _publish_defer\n",
      "    self._publish(rec, local=True)\n",
      "  File \"/Users/krc/miniforge3/envs/pytorch/lib/python3.8/site-packages/wandb/sdk/interface/interface_queue.py\", line 59, in _publish\n",
      "    self.record_q.put(record)\n",
      "  File \"/Users/krc/miniforge3/envs/pytorch/lib/python3.8/multiprocessing/queues.py\", line 82, in put\n",
      "    raise ValueError(f\"Queue {self!r} is closed\")\n",
      "ValueError: Queue <multiprocessing.queues.Queue object at 0x1247f2d30> is closed\n",
      "wandb: ERROR Internal wandb error: file data was not synced\n",
      "/Users/krc/miniforge3/envs/pytorch/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 9 leaked semaphore objects to clean up at shutdown\n",
      "  warnings.warn('resource_tracker: There appear to be %d '\n"
     ]
    }
   ],
   "source": [
    "from mmdet.datasets import build_dataset\n",
    "from mmdet.models import build_detector\n",
    "from mmdet.apis import train_detector\n",
    "\n",
    "\n",
    "# dataset 생성 및 model 설정\n",
    "\n",
    "datasets = [build_dataset(cfg.data.train)]\n",
    "model = build_detector(cfg.model)\n",
    "model.CLASSES = datasets[0].CLASSES\n",
    "# 훈련\n",
    "train_detector(model, datasets, cfg, distributed=False, validate=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a69ad1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
